<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css"/>
    <title>Technical Documentation</title>
</head>
<body>
    <main id="main-doc">

        <section class="main-section" id="Tensorflow">
            <!-- TO DO -->
            <header class="header">Tensorflow</header>
            <p>TensorFlow is an end-to-end open source platform for machine learning. TensorFlow is a rich system for managing all aspects of a machine learning system; however, this class focuses on using a particular TensorFlow API to develop and train machine learning models. See the TensorFlow documentation for complete details on the broader TensorFlow system.</p>
            <p>TensorFlow APIs are arranged hierarchically, with the high-level APIs built on the low-level APIs. Machine learning researchers use the low-level APIs to create and explore new machine learning algorithms. In this class, you will use a high-level API named tf.keras to define and train machine learning models and to make predictions. tf.keras is the TensorFlow variant of the open-source Keras API.</p>
        </section>

        <section class="main-section" id="Dense">
            <!-- TO DO -->
            <header class="header">Dense</header>
            <p>Just your regular densely-connected NN layer.</p>
            <p>Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True). These are all attributes of Dense.</p>
            <code class="language-python">
                tf.keras.layers.Dense(
                units,
                activation=None,
                use_bias=True,
                kernel_initializer='glorot_uniform',
                bias_initializer='zeros',
                kernel_regularizer=None,
                bias_regularizer=None,
                activity_regularizer=None,
                kernel_constraint=None,
                bias_constraint=None,
                **kwargs
            )
            </code>
            <code class="language-python">
                # Create a `Sequential` model and add a Dense layer as the first layer.
                model = tf.keras.models.Sequential()
                model.add(tf.keras.Input(shape=(16,)))
                model.add(tf.keras.layers.Dense(32, activation='relu'))
                # Now the model will take as input arrays of shape (None, 16)
                # and output arrays of shape (None, 32).
                # Note that after the first layer, you don't need to specify
                # the size of the input anymore:
                model.add(tf.keras.layers.Dense(32))
                model.output_shape

            </code>
            <p>Frequently used arguments: </p>
            <ul>
                <li>units: Positive integer, dimensionality of the output space.</li>
                <li>activation: 	Activation function to use. If you don't specify anything, no activation is applied (ie. "linear" activation: a(x) = x).</li>
            </ul>
        </section>

        <section class="main-section" id="Conv2D">
            <!-- TO DO -->
            <header class="header">Conv2D</header>
            <p></p>
            <code class="language-python"></code>
            <p>2D convolution layer (e.g. spatial convolution over images).</p>
            <p>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.

                When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format="channels_last". You can use None when a dimension has variable size.</p>
            <p>Frequently used arguments: </p>
            <ul>
                <li>filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).</li>
                <li>kernel_size: 	An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions. </li>
                <li>strides: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width.</li>
                <li>activation: Activation function to use. If you don't specify anything, no activation is applied.</li>
                <li>padding: One of "valid" or "same" (case-insensitive). "valid" means no padding. "same" results in padding with zeros evenly to the left/right or up/down of the input. When padding="same" and strides=1, the output has the same size as the input.</li>
            </ul>
            <code class="language-python">
                tf.keras.layers.Conv2D(
                filters,
                kernel_size,
                strides=(1, 1),
                padding='valid',
                data_format=None,
                dilation_rate=(1, 1),
                groups=1,
                activation=None,
                use_bias=True,
                kernel_initializer='glorot_uniform',
                bias_initializer='zeros',
                kernel_regularizer=None,
                bias_regularizer=None,
                activity_regularizer=None,
                kernel_constraint=None,
                bias_constraint=None,
                **kwargs
                )
            </code>
            <code class="language-python">
                # The inputs are 28x28 RGB images with `channels_last` and the batch
                # size is 4.
                input_shape = (4, 28, 28, 3)
                x = tf.random.normal(input_shape)
                y = tf.keras.layers.Conv2D(
                2, 3, activation='relu', input_shape=input_shape[1:])(x)
                print(y.shape)
                </code>
            <p></p>
        </section>

        <section class="main-section" id="MaxPooling2D">
            <!-- TO DO -->
            <header class="header">MaxPooling2D</header>
            <p>Max pooling operation for 2D spatial data.</p>
            <p>Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.</p>
            <code class="language-python">tf.keras.layers.MaxPooling2D(
                pool_size=(2, 2),
                strides=None,
                padding='valid',
                data_format=None,
                **kwargs
                )
            </code>
            <code class="language-python">
                x = tf.constant([[1., 2., 3., 4.],
                [5., 6., 7., 8.],
                [9., 10., 11., 12.]])
                x = tf.reshape(x, [1, 3, 4, 1])
                max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
                strides=(2, 2), padding='valid')
                max_pool_2d(x)
            </code>
            <p>Frequently used arguments: </p>
            <ul>
                <li>pool_size: 	integer or tuple of 2 integers, window size over which to take the maximum. (2, 2) will take the max value over a 2x2 pooling window. If only one integer is specified, the same window length will be used for both dimensions.</li>
                <li>strides: Integer, tuple of 2 integers, or None. Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to pool_size.</li>
            </ul>
            <code class="language-python"></code>
            <code class="language-python"></code>
            <p></p>
        </section>

        <section class="main-section" id="Convolutional_Neural_Networks">
            <!-- TO DO -->
            <header class="header">Convolutional Neural Networks</header>
            <p>A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm that can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image, and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics.</p>
            <code class="language-python">
                model = Sequential()


                model.add(Input(shape=(128,128,3)))
            
                model.add(Conv2D(filters=32,
                                 kernel_size = (3,3),
                                 strides=(1, 1),
                                 padding="valid",
                                 activation="relu",
                                 ))
                model.add(MaxPooling2D(pool_size = 2, strides = 2))
            
                model.add(Flatten())

                model.add(Dense(units=64,
                                activation = "relu",))
                model.add(Dense(units=3,
                                activation = "softmax",))
            </code>
            <p>The architecture of the above Sequential CNN Model is comprised of an Input layer that accepts a 128 by 128 by 3 image, with 128 representing both width and height and 3 representing the RGB values. Afterwards, a Conv2D layer was added with the necessary arguments to extract features from input images, then a MaxPooling2D layer to highlight the most prominent features of the image while reeducing the total data, then a Flatten layer to flatten the processed image into a single dimention before feeding it to a Dense layer and finally to the classification layer.</p>
            <code class="language-python">
                model.compile(loss='categorical_crossentropy',
                optimizer=Adam(),
                metrics=['acc'])
            </code>
            <p>The model was then compiled to use categorical_crossentropy because it has more than two classes and uses softmax activation for the classification layer. If the model would only have two classes, then binary_crossentropy would be a viable choice along with a sigmoid activation at the classification layer. The optimizer used was Adam because it works generally well for most image classification problems, and the metric used to asses the model was acc or accuracy.</p>
            <code class="language-python">
                model.fit(train_gen, validation_data=val_gen,
                epochs = 32)
            </code>
            <p>The model.fit starts the training of the model, the train_gen inputs the training data for the model to train on, and after training the model will then be presented with previously unseen data from the val_gen. The model will train on the whole training dataset from the train gen for 32 epochs or in other words 32 cycles in the whole dataset.</p>
            <p></p>
        </section>
        
        <!-- TO DO -->
        <nav id="navbar">
            <header>Contents</header>
            <ul>
            <li><a class="nav-link" href="#Tensorflow">Tensorflow</a></li>
            <li><a class="nav-link" href="#Dense">Dense</a></li>
            <li><a class="nav-link" href="#Conv2D">Conv2D</a></li>
            <li><a class="nav-link" href="#MaxPooling2D">MaxPooling2D</a></li>
            <li><a class="nav-link" href="#Convolutional_Neural_Networks">Convolutional Neural Networks</a></li>
            </ul>
        </nav>
    </main>
</body>
</html>